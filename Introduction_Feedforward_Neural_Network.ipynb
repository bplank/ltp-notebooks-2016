{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A neural network is computational model that has slightly different meanings in different communitites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Cognitive science view**: a computational model of the brain consisting of artificial neural perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Machine Learning view**: \n",
    "   * **Linear algebra view**: a network of perceptron-like nodes, i.e., a set of matrix multiplication operations\n",
    "   * **Graph theory view**: a computational graph model (with automatic differentiation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As the name already suggests, a neural network is a network. It can be seen as a model that is build up from basic building blocks. Lets first look at one such building block, for instance, a single perceptron. \n",
    "\n",
    "<img src=\"pics/lego.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From biological neurons to artificial neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To get started, I will first introduce a type of artificial neuron the **perceptron**. It was introduced with the well-known perceptron algorithm by Rosenblatt (1957), inspired by earlier work on McCulloch-Pitts to model neurons in the brain. In layman's terms, a neuron gets information through dendrites and if enough information is accumulated the neuron 'fires' and send information down the axon: \n",
    "\n",
    "<img src=\"pics/neuron.jpg\" width=\"350\" style=\"float: left\"><img src=\"pics/neuron-simple.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does the perceptron work?\n",
    "The basic perceptron gets **inputs** $x_1,..,x_n$ and produces an **output** $y$. It does so by **weighting** the inputs by $w_1,..,w_n$, sums up the weighted intputs and sends this weighted sum through an **activation function** $\\sigma$ doto see if the neuron \"fires\". That is, if the weighted sum is above some **threshold** it will output 1, otherwise 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mathematically, the perceptron is formulated as: \n",
    "\n",
    "$y = \\sigma(\\sum_{j=1}^d w_{kj} x_j )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can visualize the perceptron as (for a given perceptron node $k$): <img src=\"pics/perceptron.png\" width=400> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is $\\sigma$?\n",
    "\n",
    "In the perceptron $\\sigma$ is a **threshold** function. Intuitively, the perceptron only fires if the weighted sum is above some threshold. We can formulize this intuition as:\n",
    "\n",
    "\n",
    "$$\\begin{equation}\n",
    "    y=\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if} (\\sum_j w_j x_j) > threshold\\\\\n",
    "      0 & \\text{otherwise}\\\\\n",
    "    \\end{cases}\n",
    "  \\end{equation}$$\n",
    "  \n",
    "Lets rewrite the equation of the perceptron. First, notice that $\\sum_{j=1} w_{j} x_j $ is the **dot product** of the weights and input, and can be written as: \n",
    "\n",
    "$$\\sum_{j=1} w_{j} x_j = \\vec{w} \\cdot \\vec{x}$$ where $\\vec{w}$ and $\\vec{x}$ are now vectors. If it is clear from context we avoid the explicit vector notation and simply write: $w \\cdot x$. Second, we will move the threshold inside the equation by introducing $b$ the bias term $b=-threshold$. Using these two changes, the equation rewrites as:\n",
    "\n",
    "$$\\begin{equation}\n",
    "    y=\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if} (w \\cdot x + b) > 0)\\\\\n",
    "      0 & \\text{otherwise}\\\\\n",
    "    \\end{cases}\n",
    "  \\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Suppose we have a perceptron with two inputs, weights -2 and -2 and bias term 3. This is illustrated as: <img src=\"pics/and.png\">\n",
    "What function does this simple perceptron compute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def compute(input_array):\n",
    "    a = input_array[0]*-2 + input_array[1]*-2 + 1 * 3\n",
    "    if a > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "i=[0,0]\n",
    "print(compute(i))\n",
    "print(compute([0,1]))\n",
    "print(compute([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=[0,1]\n",
    "y="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* threshold\n",
    "* sigma\n",
    "* network, activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* More details in [Michael Nielsen's book chapter 1](http://neuralnetworksanddeeplearning.com/chap1.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
