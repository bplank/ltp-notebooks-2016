{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is computational model that has slightly different meanings depending on which view on takes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Cognitive science view**: a computational model of the brain consisting of artificial neural perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Machine Learning view**: \n",
    "   * **Linear algebra view**: a network of perceptron-like nodes, i.e., a set of matrix multiplication operations\n",
    "   * **Graph theory view**: a computational graph model (with automatic differentiation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name already suggests, a neural network is a network. It can be seen as a model that is build up from basic building blocks. Lets first look at one such building block, for instance, a single perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron (in 2 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, I will first introduce a type of artificial neuron the **perceptron**. It was introduced with the well-known perceptron algorithm by Rosenblatt (1957), inspired by earlier work on McCulloch-Pitts to model neurons in the brain. In layman's terms, a neuron gets information through dendrites and if enough information is accumulated the neuron 'fires' and send information down the axon: <img src=\"pics/neuron.jpg\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the perceptrons works\n",
    "So how does the perceptron work? The basic perceptron gets inputs $x_1,..,x_n$ and produces an output $y$. It does so by weighting the inputs by $w_1,..,w_n$, sums up the weighted intputs and sends this weighted sum through an *activation function* to see if the neuron \"fires\". That is, if the weighted sum is above some *threshold* it will output 1, otherwise 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, the perceptron is formulated as: \n",
    "\n",
    "$y = \\sigma(\\sum_{j=1}^k w_{ij} * x_i )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the perceptron formula as: <img src=\"pics/perceptron.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* More details in [Michael Nielsen's book chapter 1](http://neuralnetworksanddeeplearning.com/chap1.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
